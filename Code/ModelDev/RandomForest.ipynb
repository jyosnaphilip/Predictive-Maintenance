{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Regression Model ~ Jyosna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "\n",
    "https://ploomber.io/blog/nested-cv/\n",
    "\n",
    "https://machinelearningmastery.com/nested-cross-validation-for-machine-learning-with-python/\n",
    "\n",
    "https://medium.com/@maziarizadi/pickle-your-model-in-python-2bbe7dba2bbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit,GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score,root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(\"C:\\\\Users\\\\jyosn\\\\Documents\\\\GitHub\\\\Predictive-Maintenance\\\\Datasets\\\\ForModelDev\\\\XTrain.csv\")\n",
    "y_train = pd.read_csv(\"C:\\\\Users\\\\jyosn\\\\Documents\\\\GitHub\\\\Predictive-Maintenance\\\\Datasets\\\\ForModelDev\\\\YTrain.csv\")\n",
    "engine = np.array(pd.read_csv(\"C:\\\\Users\\\\jyosn\\\\Documents\\\\GitHub\\\\Predictive-Maintenance\\\\Datasets\\\\ForModelDev\\\\Engine.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=np.asarray(y_train).ravel()\n",
    "Engine=engine.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6664938496070634\n",
      "0.39281851031640014\n",
      "0.6512813872255199\n",
      "0.634681682135068\n",
      "0.5551498664247289\n",
      "0.5668824700406194\n",
      "0.48390809485095265\n",
      "0.584106303762581\n",
      "0.2644713156465103\n",
      "0.48766456778336253\n"
     ]
    }
   ],
   "source": [
    "gss_outer = GroupShuffleSplit(n_splits = 10, train_size = 0.7, random_state = 42) #n_splits refers to number of folds required\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(gss_outer.split(x_train, Y_train, Engine)):\n",
    "    xtrain = x_train.iloc[train_index, :] # Train Data from training set (70% split)\n",
    "    ytrain = y_train.iloc[train_index, :]\n",
    "    Y_train=np.asarray(ytrain).ravel()\n",
    "    xval = x_train.iloc[val_index, :] # Validation Data from training set (30% split)\n",
    "    yval = y_train.iloc[val_index, :]\n",
    "    \n",
    "    rf = RandomForestRegressor(n_estimators=100,random_state=42,min_samples_leaf=3)\n",
    "    rf.fit(xtrain, Y_train)\n",
    "    print(r2_score(rf.predict(xval), yval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyperparameter tuning using nested cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">r2=0.687, est=0.575, cfg={'ccp_alpha': 0, 'criterion': 'squared_error', 'max_depth': 8, 'min_samples_leaf': 4, 'n_estimators': 300}\n",
      ">r2=0.618, est=0.698, cfg={'ccp_alpha': 0, 'criterion': 'squared_error', 'max_depth': 6, 'min_samples_leaf': 8, 'n_estimators': 100}\n",
      ">r2=0.738, est=0.610, cfg={'ccp_alpha': 0, 'criterion': 'squared_error', 'max_depth': 6, 'min_samples_leaf': 4, 'n_estimators': 200}\n",
      ">r2=0.724, est=0.533, cfg={'ccp_alpha': 0, 'criterion': 'squared_error', 'max_depth': 8, 'min_samples_leaf': 4, 'n_estimators': 200}\n",
      ">r2=0.686, est=0.624, cfg={'ccp_alpha': 0, 'criterion': 'squared_error', 'max_depth': 6, 'min_samples_leaf': 4, 'n_estimators': 300}\n",
      ">r2=0.624, est=0.637, cfg={'ccp_alpha': 0, 'criterion': 'squared_error', 'max_depth': 6, 'min_samples_leaf': 10, 'n_estimators': 300}\n",
      ">r2=0.695, est=0.595, cfg={'ccp_alpha': 0, 'criterion': 'squared_error', 'max_depth': 6, 'min_samples_leaf': 10, 'n_estimators': 200}\n",
      ">r2=0.653, est=0.664, cfg={'ccp_alpha': 0, 'criterion': 'squared_error', 'max_depth': 6, 'min_samples_leaf': 4, 'n_estimators': 100}\n",
      ">r2=0.605, est=0.768, cfg={'ccp_alpha': 0, 'criterion': 'squared_error', 'max_depth': 6, 'min_samples_leaf': 4, 'n_estimators': 200}\n",
      ">r2=0.628, est=0.739, cfg={'ccp_alpha': 0, 'criterion': 'squared_error', 'max_depth': 6, 'min_samples_leaf': 10, 'n_estimators': 200}\n",
      "R2: 0.666 (0.044)\n",
      "RMSE: 39.489 (3.595)\n"
     ]
    }
   ],
   "source": [
    "# configure the cross-validation procedure\n",
    "from numpy import mean, std\n",
    "\n",
    "\n",
    "# enumerate splits\n",
    "outer_results = {\"r2\":[],\"rmse\":[]}\n",
    "for i,(train_ix, test_ix) in enumerate(gss_outer.split(x_train, y_train, engine)):\n",
    "    # split data\n",
    "    X_train, X_test = x_train.iloc[train_ix, :], x_train.iloc[test_ix, :]\n",
    "    Y_train, Y_test = y_train.iloc[train_ix], y_train.iloc[test_ix]\n",
    "    Engine=engine[train_ix]\n",
    "    Y_train=np.asarray(Y_train).ravel()\n",
    "    Engine=Engine.ravel()\n",
    "    # configure the cross-validation procedure\n",
    "    gss_inner =  GroupShuffleSplit(n_splits = 3, train_size = 0.7, random_state = 42)\n",
    "    # define the model\n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "    para={\"n_estimators\":[100,200,300],\"max_depth\":[6,8,10,12,14],\"min_samples_leaf\":[4,6,8,10],\"criterion\":[\"squared_error\"],\"ccp_alpha\":[0,1,2] }\n",
    "\n",
    "    # define search\n",
    "    search = GridSearchCV(rf, param_grid=para, scoring=['r2','neg_root_mean_squared_error'], cv=gss_inner, refit='r2')\n",
    "    # execute search\n",
    "    result = search.fit(X_train, Y_train,groups=Engine)\n",
    "    # get the best performing model fit on the whole training set\n",
    "    best_model = result.best_estimator_\n",
    "    # evaluate model on the hold out dataset\n",
    "    yhat = best_model.predict(X_test)\n",
    "    # evaluate the model\n",
    "    r2 = r2_score(Y_test, yhat)\n",
    "    rmse=root_mean_squared_error(Y_test,yhat)\n",
    "    # store the result\n",
    "    outer_results[\"r2\"].append(r2)\n",
    "    outer_results[\"rmse\"].append(rmse)\n",
    "    # report progress\n",
    "    print('>r2=%.3f, est=%.3f, cfg=%s' % (r2, result.best_score_, result.best_params_))\n",
    "# summarize the estimated performance of the model\n",
    "print('R2: %.3f (%.3f)' % (mean(outer_results[\"r2\"]), std(outer_results[\"r2\"])))\n",
    "print('RMSE: %.3f (%.3f)' % (mean(outer_results[\"rmse\"]), std(outer_results[\"rmse\"])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output\n",
    "\n",
    ">r2=0.687, est=0.575, cfg={'ccp_alpha': 0, 'criterion': 'squared_error', 'max_depth': 8, 'min_samples_leaf': 4, 'n_estimators': 300}\n",
    "\n",
    ">r2=0.618, est=0.698, cfg={'ccp_alpha': 0, 'criterion': 'squared_error', 'max_depth': 6, 'min_samples_leaf': 8, 'n_estimators': 100}\n",
    "\n",
    ">r2=0.738, est=0.610, cfg={'ccp_alpha': 0, 'criterion': 'squared_error', 'max_depth': 6, 'min_samples_leaf': 4, 'n_estimators': 200}\n",
    "\n",
    ">r2=0.724, est=0.533, cfg={'ccp_alpha': 0, 'criterion': 'squared_error', 'max_depth': 8, 'min_samples_leaf': 4, 'n_estimators': 200}\n",
    "\n",
    ">r2=0.686, est=0.624, cfg={'ccp_alpha': 0, 'criterion': 'squared_error', 'max_depth': 6, 'min_samples_leaf': 4, 'n_estimators': 300}\n",
    "\n",
    ">r2=0.624, est=0.637, cfg={'ccp_alpha': 0, 'criterion': 'squared_error', 'max_depth': 6, 'min_samples_leaf': 10, 'n_estimators': 300}\n",
    "\n",
    ">r2=0.695, est=0.595, cfg={'ccp_alpha': 0, 'criterion': 'squared_error', 'max_depth': 6, 'min_samples_leaf': 10, 'n_estimators': 200}\n",
    "\n",
    ">r2=0.653, est=0.664, cfg={'ccp_alpha': 0, 'criterion': 'squared_error', 'max_depth': 6, 'min_samples_leaf': 4, 'n_estimators': 100}\n",
    "\n",
    ">r2=0.605, est=0.768, cfg={'ccp_alpha': 0, 'criterion': 'squared_error', 'max_depth': 6, 'min_samples_leaf': 4, 'n_estimators': 200}\n",
    "\n",
    ">r2=0.628, est=0.739, cfg={'ccp_alpha': 0, 'criterion': 'squared_error', 'max_depth': 6, 'min_samples_leaf': 10, 'n_estimators': 200}\n",
    "\n",
    "R2: 0.666 (0.044)\n",
    "\n",
    "RMSE: 39.489 (3.595)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(rf, param_grid=para, scoring=['r2','neg_root_mean_squared_error'], cv=gss_inner, refit='r2')\n",
    "result = search.fit(X_train, Y_train,groups=Engine)\n",
    "# get the best performing model fit on the whole training set\n",
    "best_model = result.best_estimator_\n",
    "# evaluate model on the hold out dataset\n",
    "yhat = best_model.predict(X_test)\n",
    "# evaluate the model\n",
    "r2 = r2_score(Y_test, yhat)\n",
    "rmse=root_mean_squared_error(Y_test,yhat)\n",
    "# store the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6277776059115391 41.84085429841219\n"
     ]
    }
   ],
   "source": [
    "print(r2,rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(best_model, open('random_forest_model.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
