{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost    ~Jyosna Philip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score,root_mean_squared_error #Additional scklearn functions\n",
    "from sklearn.model_selection import GroupShuffleSplit,GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(\"C:\\\\Users\\\\jyosn\\\\Documents\\\\GitHub\\\\Predictive-Maintenance\\\\Datasets\\\\ForModelDev\\\\XTrain.csv\")\n",
    "y_train = pd.read_csv(\"C:\\\\Users\\\\jyosn\\\\Documents\\\\GitHub\\\\Predictive-Maintenance\\\\Datasets\\\\ForModelDev\\\\YTrain.csv\")\n",
    "engine = np.array(pd.read_csv(\"C:\\\\Users\\\\jyosn\\\\Documents\\\\GitHub\\\\Predictive-Maintenance\\\\Datasets\\\\ForModelDev\\\\Engine.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Engine=engine.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xg boost -base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6388315862709321\n",
      "39.16098501762964\n"
     ]
    }
   ],
   "source": [
    "gss_b = GroupShuffleSplit(n_splits = 1, train_size = 0.7, random_state = 42)\n",
    "train_index_b,val_index_b=next(gss_b.split(x_train, y_train, engine))\n",
    "Y_train=np.asarray(y_train).ravel()\n",
    "xgb_b = XGBRegressor(n_estimators=70, max_depth=8, eta=0.2, subsample=0.7, colsample_bytree=0.8)\n",
    "xgb_b.fit(x_train.iloc[train_index_b,:], Y_train[train_index_b])\n",
    "prediction=xgb_b.predict(x_train.iloc[val_index_b,:])\n",
    "print(r2_score( Y_train[val_index_b],prediction))\n",
    "print(root_mean_squared_error( Y_train[val_index_b],prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.6388315862709321\n",
    "\n",
    "39.16098501762964"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgb with cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.617 (0.053)\n",
      "RMSE: 42.284 (3.890)\n"
     ]
    }
   ],
   "source": [
    "gss_outer = GroupShuffleSplit(n_splits = 10, train_size = 0.7, random_state = 42) #n_splits refers to number of folds required\n",
    "r2=[]\n",
    "rmse=[]\n",
    "for i, (train_index, val_index) in enumerate(gss_outer.split(x_train, y_train, Engine)):\n",
    "    xtrain = x_train.iloc[train_index, :] # Train Data from training set (70% split)\n",
    "    ytrain = y_train.iloc[train_index, :]\n",
    "    Y_train=np.asarray(ytrain).ravel()\n",
    "    xval = x_train.iloc[val_index, :] # Validation Data from training set (30% split)\n",
    "    yval = y_train.iloc[val_index, :]\n",
    "    \n",
    "    xgb_cv =XGBRegressor(n_estimators=100, max_depth=7, eta=0.1)\n",
    "    xgb_cv.fit(xtrain, Y_train)\n",
    "    r2.append(r2_score( yval,xgb_cv.predict(xval)))\n",
    "    rmse.append(root_mean_squared_error(yval,xgb_cv.predict(xval)))\n",
    "print('R2: %.3f (%.3f)' % (np.mean(r2), np.std(r2)))\n",
    "print('RMSE: %.3f (%.3f)' % (np.mean(rmse), np.std(rmse)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R2: 0.617 (0.053)\n",
    "\n",
    "RMSE: 42.284 (3.890)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgb with gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:  0.7051736007072658\n",
      "rmse:  35.3819618955303\n"
     ]
    }
   ],
   "source": [
    "gss_grid =  GroupShuffleSplit(n_splits = 1, train_size = 0.7, random_state = 42)\n",
    "\n",
    "xgb_grid = XGBRegressor(seed=42)\n",
    "para={\"learning_rate\":[0.05,0.1,0.2],\"n_estimators\":[70,100,200,300],\"max_depth\":[5,6,7,8],\"min_child_weight\":[50,100] }\n",
    "train_index_grid,val_index_grid=next(gss_grid.split(x_train, y_train, Engine))\n",
    "# define search\n",
    "search = GridSearchCV(xgb_grid, param_grid=para, scoring=['r2','neg_root_mean_squared_error'], cv=gss_grid, refit='r2')\n",
    "# execute search\n",
    "Y_train=np.asarray(y_train).ravel()\n",
    "result = search.fit(x_train.iloc[train_index_grid,:], Y_train[train_index_grid],groups=Engine[train_index_grid])\n",
    "# get the best performing model fit on the whole training set\n",
    "best_model = result.best_estimator_\n",
    "yhat = best_model.predict(x_train.iloc[val_index_grid,:])\n",
    "# evaluate the model\n",
    "r2 = r2_score(Y_train[val_index_grid], yhat)\n",
    "rmse=root_mean_squared_error(Y_train[val_index_grid],yhat)\n",
    "print(\"r2: \",r2)\n",
    "print(\"rmse: \",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r2:  0.7051736007072658\n",
    "\n",
    "rmse:  35.3819618955303"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.05,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 100,\n",
       " 'n_estimators': 70}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'learning_rate': 0.05,\n",
    " 'max_depth': 5,\n",
    " 'min_child_weight': 100,\n",
    " 'n_estimators': 70}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gradient boosting with gridsearch cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 200, 'n_estimators': 70}\n",
      "r2:  0.7017800607793739\n",
      "rmse:  35.585007763032074\n"
     ]
    }
   ],
   "source": [
    "gss_grid_cv =  GroupShuffleSplit(n_splits = 10, train_size = 0.7, random_state = 42)\n",
    "\n",
    "xgb_grid_cv =XGBRegressor(seed=42)\n",
    "para={\"learning_rate\":[0.05,0.1,0.2],\"n_estimators\":[70,100,200,300],\"max_depth\":[5,6,7,8],\"min_child_weight\":[70,100,150,200] }\n",
    "train_index_grid_cv,val_index_grid_cv=next(gss_grid_cv.split(x_train, y_train, Engine))\n",
    "# define search\n",
    "search = GridSearchCV(xgb_grid_cv, param_grid=para, scoring=['r2','neg_root_mean_squared_error'], cv=gss_grid_cv, refit='r2')\n",
    "# execute search\n",
    "Y_train=np.asarray(y_train).ravel()\n",
    "result = search.fit(x_train.iloc[train_index_grid_cv,:], Y_train[train_index_grid_cv],groups=Engine[train_index_grid_cv])\n",
    "# get the best performing model fit on the whole training set\n",
    "best_model = result.best_estimator_\n",
    "print(result.best_params_)\n",
    "yhat = best_model.predict(x_train.iloc[val_index_grid_cv,:])\n",
    "# evaluate the model\n",
    "r2 = r2_score(Y_train[val_index_grid_cv], yhat)\n",
    "rmse=root_mean_squared_error(Y_train[val_index_grid_cv],yhat)\n",
    "print(\"r2: \",r2)\n",
    "print(\"rmse: \",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 200, 'n_estimators': 70}\n",
    "\n",
    "r2:  0.7017800607793739\n",
    "\n",
    "rmse:  35.585007763032074"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(best_model, open('xgb_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gradient boosting with nested gridsearchcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">r2=0.702, est=0.593, cfg={'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 200, 'n_estimators': 70}\n",
      ">r2=0.603, est=0.688, cfg={'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 150, 'n_estimators': 70}\n",
      ">r2=0.709, est=0.629, cfg={'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 200, 'n_estimators': 70}\n",
      ">r2=0.749, est=0.544, cfg={'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 200, 'n_estimators': 70}\n",
      ">r2=0.695, est=0.621, cfg={'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 200, 'n_estimators': 70}\n",
      ">r2=0.641, est=0.628, cfg={'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 100, 'n_estimators': 70}\n",
      ">r2=0.694, est=0.592, cfg={'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 200, 'n_estimators': 70}\n",
      ">r2=0.648, est=0.676, cfg={'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 200, 'n_estimators': 70}\n",
      ">r2=0.607, est=0.769, cfg={'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 200, 'n_estimators': 70}\n",
      ">r2=0.594, est=0.743, cfg={'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 200, 'n_estimators': 70}\n",
      "R2: 0.664 (0.050)\n",
      "RMSE: 39.547 (3.804)\n"
     ]
    }
   ],
   "source": [
    "gss_outer = GroupShuffleSplit(n_splits = 10, train_size = 0.7, random_state = 42) #n_splits refers to number of folds required\n",
    "\n",
    "# enumerate splits\n",
    "outer_results = {\"r2\":[],\"rmse\":[]}\n",
    "for i,(train_ix, test_ix) in enumerate(gss_outer.split(x_train, y_train, engine)):\n",
    "    # split data\n",
    "    X_train, X_test = x_train.iloc[train_ix, :], x_train.iloc[test_ix, :]\n",
    "    Y_train, Y_test = y_train.iloc[train_ix], y_train.iloc[test_ix]\n",
    "    Engine=engine[train_ix]\n",
    "    Y_train=np.asarray(Y_train).ravel()\n",
    "    Engine=Engine.ravel()\n",
    "    # configure the cross-validation procedure\n",
    "    gss_inner =  GroupShuffleSplit(n_splits = 3, train_size = 0.7, random_state = 42)\n",
    "    # define the model\n",
    "    xgb = XGBRegressor(seed=42)\n",
    "    para={\"learning_rate\":[0.05,0.1,0.2],\"n_estimators\":[70,100,200,300],\"max_depth\":[5,6,7,8],\"min_child_weight\":[70,100,150,200] }\n",
    "\n",
    "    # define search\n",
    "    search = GridSearchCV(xgb, param_grid=para, scoring=['r2','neg_root_mean_squared_error'], cv=gss_inner, refit='r2')\n",
    "    # execute search\n",
    "    result = search.fit(X_train, Y_train,groups=Engine)\n",
    "    # get the best performing model fit on the whole training set\n",
    "    best_model = result.best_estimator_\n",
    "    # evaluate model on the hold out dataset\n",
    "    yhat = best_model.predict(X_test)\n",
    "    # evaluate the model\n",
    "    r2 = r2_score(Y_test, yhat)\n",
    "    rmse=root_mean_squared_error(Y_test,yhat)\n",
    "    # store the result\n",
    "    outer_results[\"r2\"].append(r2)\n",
    "    outer_results[\"rmse\"].append(rmse)\n",
    "    # report progress\n",
    "    print('>r2=%.3f, est=%.3f, cfg=%s' % (r2, result.best_score_, result.best_params_))\n",
    "# summarize the estimated performance of the model\n",
    "print('R2: %.3f (%.3f)' % (np.mean(outer_results[\"r2\"]), np.std(outer_results[\"r2\"])))\n",
    "print('RMSE: %.3f (%.3f)' % (np.mean(outer_results[\"rmse\"]), np.std(outer_results[\"rmse\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">r2=0.702, est=0.593, cfg={'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 200, 'n_estimators': 70}\n",
    "\n",
    ">r2=0.603, est=0.688, cfg={'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 150, 'n_estimators': 70}\n",
    "\n",
    ">r2=0.709, est=0.629, cfg={'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 200, 'n_estimators': 70}\n",
    "\n",
    ">r2=0.749, est=0.544, cfg={'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 200, 'n_estimators': 70}\n",
    "\n",
    ">r2=0.695, est=0.621, cfg={'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 200, 'n_estimators': 70}\n",
    "\n",
    ">r2=0.641, est=0.628, cfg={'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 100, 'n_estimators': 70}\n",
    "\n",
    ">r2=0.694, est=0.592, cfg={'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 200, 'n_estimators': 70}\n",
    "\n",
    ">r2=0.648, est=0.676, cfg={'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 200, 'n_estimators': 70}\n",
    "\n",
    ">r2=0.607, est=0.769, cfg={'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 200, 'n_estimators': 70}\n",
    "\n",
    ">r2=0.594, est=0.743, cfg={'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 200, 'n_estimators': 70}\n",
    "\n",
    "R2: 0.664 (0.050)\n",
    "RMSE: 39.547 (3.804)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
